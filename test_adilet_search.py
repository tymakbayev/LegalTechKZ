"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞ –Ω–∞ adilet.zan.kz

–ó–∞–ø—É—Å–∫:
    python test_adilet_search.py
"""

import requests
from bs4 import BeautifulSoup
import re
from urllib.parse import urljoin, parse_qs, urlparse

def test_main_page():
    """–ò–∑—É—á–∏—Ç—å –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ —Ñ–æ—Ä–º—É –ø–æ–∏—Å–∫–∞"""
    print("=" * 80)
    print("–¢–ï–°–¢ 1: –ò–∑—É—á–µ–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã adilet.zan.kz")
    print("=" * 80)

    try:
        response = requests.get("https://adilet.zan.kz/rus", timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')

        # –ò—â–µ–º —Ñ–æ—Ä–º—É –ø–æ–∏—Å–∫–∞
        search_forms = soup.find_all('form')
        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ñ–æ—Ä–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(search_forms)}")

        for i, form in enumerate(search_forms, 1):
            print(f"\nüìã –§–æ—Ä–º–∞ {i}:")
            print(f"   Action: {form.get('action', '–ù–µ —É–∫–∞–∑–∞–Ω')}")
            print(f"   Method: {form.get('method', 'GET').upper()}")
            print(f"   ID: {form.get('id', '–ù–µ—Ç')}")
            print(f"   Class: {form.get('class', '–ù–µ—Ç')}")

            # –ò—â–µ–º –ø–æ–ª—è –≤–≤–æ–¥–∞
            inputs = form.find_all(['input', 'select', 'textarea'])
            if inputs:
                print(f"   –ü–æ–ª—è ({len(inputs)}):")
                for inp in inputs:
                    name = inp.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')
                    inp_type = inp.get('type', inp.name)
                    placeholder = inp.get('placeholder', '')
                    print(f"      - {name} ({inp_type}): {placeholder}")

        # –ò—â–µ–º –∫–Ω–æ–ø–∫—É "–ò—Å–∫–∞—Ç—å"
        search_buttons = soup.find_all('button', string=re.compile(r'–ò—Å–∫–∞—Ç—å|–ü–æ–∏—Å–∫', re.I))
        search_buttons += soup.find_all('input', {'type': 'submit', 'value': re.compile(r'–ò—Å–∫–∞—Ç—å|–ü–æ–∏—Å–∫', re.I)})

        print(f"\nüîç –ù–∞–π–¥–µ–Ω–æ –∫–Ω–æ–ø–æ–∫ –ø–æ–∏—Å–∫–∞: {len(search_buttons)}")

        # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
        adv_search = soup.find('a', href=re.compile(r'search/advanced|—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π', re.I))
        if adv_search:
            print(f"\nüîó –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫: {adv_search.get('href')}")

        return True

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


def test_advanced_search():
    """–ò–∑—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    print("\n" + "=" * 80)
    print("–¢–ï–°–¢ 2: –ò–∑—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")
    print("=" * 80)

    try:
        response = requests.get("https://adilet.zan.kz/rus/search/advanced", timeout=10)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, 'html.parser')

        # –ò—â–µ–º —Ñ–æ—Ä–º—É
        form = soup.find('form')
        if form:
            print(f"\nüìã –§–æ—Ä–º–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
            print(f"   Action: {form.get('action', '–ù–µ —É–∫–∞–∑–∞–Ω')}")
            print(f"   Method: {form.get('method', 'GET').upper()}")

            # –í—Å–µ –ø–æ–ª—è
            inputs = form.find_all(['input', 'select', 'textarea'])
            print(f"\n   –ü–æ–ª—è –ø–æ–∏—Å–∫–∞ ({len(inputs)}):")

            for inp in inputs:
                name = inp.get('name', '–ë–µ–∑ –∏–º–µ–Ω–∏')
                inp_type = inp.get('type', inp.name)
                placeholder = inp.get('placeholder', '')
                value = inp.get('value', '')

                # –î–ª—è select - –ø–æ–∫–∞–∑–∞—Ç—å –æ–ø—Ü–∏–∏
                if inp.name == 'select':
                    options = inp.find_all('option')
                    opts_text = ', '.join([opt.get_text(strip=True) for opt in options[:5]])
                    print(f"      - {name} (select): {opts_text}...")
                else:
                    print(f"      - {name} ({inp_type}): {placeholder} {value}")

        return True

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


def test_search_query(query="–ù–∞–ª–æ–≥–æ–≤—ã–π –∫–æ–¥–µ–∫—Å"):
    """–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫ –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å URL"""
    print("\n" + "=" * 80)
    print(f"–¢–ï–°–¢ 3: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞ '{query}'")
    print("=" * 80)

    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã URL
    search_urls = [
        f"https://adilet.zan.kz/rus/search/docs?q={query}",
        f"https://adilet.zan.kz/rus/search?query={query}",
        f"https://adilet.zan.kz/rus/search/docs?text={query}",
        f"https://adilet.zan.kz/rus/search/docs?search={query}",
    ]

    for url in search_urls:
        print(f"\nüîç –ü—Ä–æ–±—É–µ–º: {url}")
        try:
            response = requests.get(url, timeout=10, allow_redirects=True)

            print(f"   –°—Ç–∞—Ç—É—Å: {response.status_code}")
            print(f"   –ò—Ç–æ–≥–æ–≤—ã–π URL: {response.url}")

            if response.status_code == 200:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                soup = BeautifulSoup(response.text, 'html.parser')

                # –ò—â–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
                results = soup.find_all('a', href=re.compile(r'/rus/docs/[A-Z]'))
                print(f"   –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã: {len(results)}")

                if results:
                    print(f"\n   ‚úÖ –†–ê–ë–û–¢–ê–ï–¢! –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
                    for i, link in enumerate(results[:3], 1):
                        print(f"      {i}. {link.get_text(strip=True)[:70]}...")
                        print(f"         URL: {link.get('href')}")

                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º URL —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    parsed = urlparse(response.url)
                    params = parse_qs(parsed.query)
                    print(f"\n   üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞:")
                    for key, value in params.items():
                        print(f"      {key} = {value}")

                    return True

        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")

    return False


def analyze_document_urls():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É URL –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    print("\n" + "=" * 80)
    print("–¢–ï–°–¢ 4: –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã URL –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print("=" * 80)

    # –ü—Ä–∏–º–µ—Ä—ã –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö URL –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    test_urls = [
        "https://adilet.zan.kz/rus/docs/K1700000120",  # –ù–∞–ª–æ–≥–æ–≤—ã–π –∫–æ–¥–µ–∫—Å
        "https://adilet.zan.kz/rus/docs/Z1500000401",  # –ó–∞–∫–æ–Ω
    ]

    for url in test_urls:
        print(f"\nüìÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º: {url}")
        try:
            response = requests.get(url, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')

                title = soup.find('h1')
                if title:
                    print(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {title.get_text(strip=True)[:100]}...")

                # –ò—â–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                meta_date = soup.find(string=re.compile(r'\d{2}\.\d{2}\.\d{4}'))
                if meta_date:
                    print(f"   –î–∞—Ç–∞: {meta_date.strip()}")

                # –ò—â–µ–º –Ω–æ–º–µ—Ä
                doc_number = soup.find(string=re.compile(r'‚Ññ.*\d+-[IVX]+'))
                if doc_number:
                    print(f"   –ù–æ–º–µ—Ä: {doc_number.strip()}")

        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {e}")


def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("\n")
    print("‚ïî" + "=" * 78 + "‚ïó")
    print("‚ïë" + " " * 20 + "–ê–ù–ê–õ–ò–ó –ü–û–ò–°–ö–ê –ù–ê ADILET.ZAN.KZ" + " " * 28 + "‚ïë")
    print("‚ïö" + "=" * 78 + "‚ïù")
    print()

    results = {
        "main_page": test_main_page(),
        "advanced_search": test_advanced_search(),
        "search_query": test_search_query("–ù–∞–ª–æ–≥–æ–≤—ã–π –∫–æ–¥–µ–∫—Å"),
        "document_urls": analyze_document_urls()
    }

    print("\n" + "=" * 80)
    print("–ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 80)

    for test_name, result in results.items():
        status = "‚úÖ –£—Å–ø–µ—à–Ω–æ" if result else "‚ùå –û—à–∏–±–∫–∞"
        print(f"{test_name}: {status}")

    print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("   1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ –≤ AdiletSearchTool")
    print("   2. –û–±–Ω–æ–≤–∏—Ç–µ _build_search_params() —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ –ø–æ–ª–µ–π")
    print("   3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ SEARCH_URL –Ω–∞ –æ—Å–Ω–æ–≤–µ working URL")
    print("   4. –û–±–Ω–æ–≤–∏—Ç–µ –ø–∞—Ä—Å–µ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã HTML\n")


if __name__ == "__main__":
    main()
