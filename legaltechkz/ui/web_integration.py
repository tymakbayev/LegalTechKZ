"""
–ú–æ–¥—É–ª—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Web-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ —Å —Å–∏—Å—Ç–µ–º–æ–π –ø—Ä–∞–≤–æ–≤–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã.

–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–≤—è–∑—å –º–µ–∂–¥—É Streamlit UI –∏ backend –ª–æ–≥–∏–∫–æ–π:
- –ó–∞–ø—É—Å–∫ pipeline —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –∞–Ω–∞–ª–∏–∑–∞
- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è UI
"""

import logging
from typing import Dict, Any, List, Optional, Callable
from dataclasses import dataclass
from datetime import datetime
import json

from legaltechkz.utils.logging_config import setup_logging, create_session_log_dir
from legaltechkz.expertise.document_parser import NPADocumentParser, DocumentFragment
from legaltechkz.expertise.completeness_validator import CompletenessValidator
from legaltechkz.expertise.expert_agents import (
    RelevanceFilterAgent,
    ConstitutionalityFilterAgent,
    SystemIntegrationFilterAgent,
    LegalTechnicalExpertAgent,
    AntiCorruptionExpertAgent,
    GenderExpertAgent
)
# ReAct –∞–≥–µ–Ω—Ç—ã - –Ω–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–º –º—ã—à–ª–µ–Ω–∏–µ–º
from legaltechkz.agents.constitutionality_react_agent import ConstitutionalityReActAgent
from legaltechkz.models.model_router import ModelRouter


@dataclass
class ExpertiseProgress:
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã."""
    current_stage: int
    total_stages: int
    stage_name: str
    articles_processed: int
    total_articles: int
    is_complete: bool
    errors: List[str]


@dataclass
class StageResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–¥–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã."""
    stage_name: str
    stage_number: int
    status: str  # "success", "warning", "error"
    articles_analyzed: int
    issues_found: int
    recommendations: List[str]
    detailed_results: Dict[str, Any]
    processing_time: float


class WebExpertiseController:
    """
    –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–º —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –∏–∑ web-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.
    """

    def __init__(self, use_react_agents: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞.

        Args:
            use_react_agents: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ReAct –∞–≥–µ–Ω—Ç–æ–≤ (True) –∏–ª–∏ —Å—Ç–∞—Ä—ã—Ö batch –∞–≥–µ–Ω—Ç–æ–≤ (False)
        """
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –ø–∞–ø–∫—É ./logs
        session_name = f"expertise_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        setup_logging(log_level="INFO", session_name=session_name)

        self.parser = NPADocumentParser()
        self.model_router = ModelRouter(enable_auto_selection=True)
        self.validator: Optional[CompletenessValidator] = None
        self.fragments: List[DocumentFragment] = []
        self.current_log_file = f"logs/{session_name}.log"
        self.use_react_agents = use_react_agents

        self.logger = logging.getLogger(__name__)
        self.logger.info("WebExpertiseController –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        self.logger.info(f"–†–µ–∂–∏–º –∞–≥–µ–Ω—Ç–æ–≤: {'ReAct (–∞–≤—Ç–æ–Ω–æ–º–Ω—ã–µ)' if use_react_agents else 'Batch (–ø—Ä–æ—Å—Ç—ã–µ)'}")
        self.logger.info(f"–õ–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤: {self.current_log_file}")

    def parse_document(self, document_text: str) -> Dict[str, Any]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã.

        Args:
            document_text: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ù–ü–ê

        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        try:
            self.fragments = self.parser.parse(document_text)

            if not self.fragments:
                return {
                    "success": False,
                    "error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ç–µ–∫—Å—Ç–∞.",
                    "fragments_count": 0
                }

            # –°–æ–∑–¥–∞—Ç—å –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –ø–æ–ª–Ω–æ—Ç—ã
            self.validator = CompletenessValidator(self.fragments)

            # –ü–æ–¥—Å—á–µ—Ç —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            articles = [f for f in self.fragments if f.type == "article"]
            chapters = [f for f in self.fragments if f.type == "chapter"]
            paragraphs = [f for f in self.fragments if f.type == "paragraph"]

            return {
                "success": True,
                "fragments_count": len(self.fragments),
                "articles_count": len(articles),
                "chapters_count": len(chapters),
                "paragraphs_count": len(paragraphs),
                "table_of_contents": self.validator.generate_checklist_text(),
                "fragments": self.fragments
            }

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return {
                "success": False,
                "error": str(e),
                "fragments_count": 0
            }

    def run_expertise_pipeline(
        self,
        document_text: str,
        document_metadata: Dict[str, str],
        stages: Dict[str, bool],
        options: Dict[str, bool],
        progress_callback: Optional[Callable[[ExpertiseProgress], None]] = None
    ) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ pipeline –ø—Ä–∞–≤–æ–≤–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã.

        Args:
            document_text: –¢–µ–∫—Å—Ç –ù–ü–ê
            document_metadata: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            stages: –ö–∞–∫–∏–µ —ç—Ç–∞–ø—ã –≤—ã–ø–æ–ª–Ω—è—Ç—å
            options: –û–ø—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (caching, thinking, etc.)
            progress_callback: Callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã
        """
        start_time = datetime.now()

        try:
            # –®–∞–≥ 1: –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            parse_result = self.parse_document(document_text)

            if not parse_result["success"]:
                return {
                    "success": False,
                    "error": parse_result["error"],
                    "stage": "parsing"
                }

            # –ê–∫—Ç–∏–≤–Ω—ã–µ —ç—Ç–∞–ø—ã
            stage_config = [
                ("relevance", "–§–∏–ª—å—Ç—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"),
                ("constitutionality", "–§–∏–ª—å—Ç—Ä –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏"),
                ("system_integration", "–§–∏–ª—å—Ç—Ä –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"),
                ("legal_technical", "–Æ—Ä–∏–¥–∏–∫–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞"),
                ("anti_corruption", "–ê–Ω—Ç–∏–∫–æ—Ä—Ä—É–ø—Ü–∏–æ–Ω–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞"),
                ("gender", "–ì–µ–Ω–¥–µ—Ä–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞")
            ]

            active_stages = [(k, n) for k, n in stage_config if stages.get(k, False)]
            total_stages = len(active_stages)

            if total_stages == 0:
                return {
                    "success": False,
                    "error": "–ù–µ –≤—ã–±—Ä–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã",
                    "stage": "configuration"
                }

            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç—Ç–∞–ø–æ–≤
            stage_results: List[StageResult] = []

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —ç—Ç–∞–ø–æ–≤
            for i, (stage_key, stage_name) in enumerate(active_stages, 1):
                stage_start = datetime.now()

                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                if progress_callback:
                    progress = ExpertiseProgress(
                        current_stage=i,
                        total_stages=total_stages,
                        stage_name=stage_name,
                        articles_processed=0,
                        total_articles=parse_result["articles_count"],
                        is_complete=False,
                        errors=[]
                    )
                    progress_callback(progress)

                # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —ç—Ç–∞–ø–∞
                stage_result = self._execute_stage(
                    stage_key=stage_key,
                    stage_name=stage_name,
                    stage_number=i,
                    options=options
                )

                stage_duration = (datetime.now() - stage_start).total_seconds()
                stage_result.processing_time = stage_duration

                stage_results.append(stage_result)

            # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–ª–Ω–æ—Ç—ã
            completeness_report = self.validator.get_completion_report()

            # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            total_issues = sum(r.issues_found for r in stage_results)
            all_successful = all(r.status == "success" for r in stage_results)

            # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞)
            quality_score = 100
            if total_issues > 0:
                quality_score -= min(total_issues * 5, 30)
            if not completeness_report["is_complete"]:
                quality_score -= 20

            quality_score = max(quality_score, 0)

            # –ò—Ç–æ–≥–æ–≤—ã–π –≤–µ—Ä–¥–∏–∫—Ç
            if quality_score >= 90 and all_successful:
                verdict = "–î–æ–∫—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ –ø—Ä–∏–Ω—è—Ç–∏—é"
                verdict_status = "success"
            elif quality_score >= 70:
                verdict = "–î–æ–∫—É–º–µ–Ω—Ç —Ç—Ä–µ–±—É–µ—Ç –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–æ—Ä–∞–±–æ—Ç–æ–∫"
                verdict_status = "warning"
            else:
                verdict = "–î–æ–∫—É–º–µ–Ω—Ç —Ç—Ä–µ–±—É–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–æ—Ä–∞–±–æ—Ç–æ–∫"
                verdict_status = "error"

            # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            total_duration = (datetime.now() - start_time).total_seconds()

            return {
                "success": True,
                "document": document_metadata,
                "parsing": parse_result,
                "stages_completed": len(stage_results),
                "stage_results": [self._stage_result_to_dict(r) for r in stage_results],
                "completeness": completeness_report,
                "overall": {
                    "quality_score": quality_score,
                    "total_issues": total_issues,
                    "verdict": verdict,
                    "verdict_status": verdict_status,
                    "ready_for_approval": quality_score >= 80 and all_successful,
                    "processing_time": total_duration
                },
                "log_file": self.current_log_file,  # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–æ–≤
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã: {e}")
            import traceback
            return {
                "success": False,
                "error": str(e),
                "traceback": traceback.format_exc(),
                "stage": "execution"
            }

    def _execute_stage(
        self,
        stage_key: str,
        stage_name: str,
        stage_number: int,
        options: Dict[str, bool]
    ) -> StageResult:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —ç—Ç–∞–ø–∞ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏.

        Args:
            stage_key: –ö–ª—é—á —ç—Ç–∞–ø–∞
            stage_name: –ù–∞–∑–≤–∞–Ω–∏–µ —ç—Ç–∞–ø–∞
            stage_number: –ù–æ–º–µ—Ä —ç—Ç–∞–ø–∞
            options: –û–ø—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —ç—Ç–∞–ø–∞
        """
        try:
            articles = [f for f in self.fragments if f.type == "article"]

            if not articles:
                self.logger.warning(f"–ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ —ç—Ç–∞–ø–µ '{stage_name}'")
                return StageResult(
                    stage_name=stage_name,
                    stage_number=stage_number,
                    status="warning",
                    articles_analyzed=0,
                    issues_found=0,
                    recommendations=["–°—Ç–∞—Ç—å–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"],
                    detailed_results={},
                    processing_time=0.0
                )

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ–∫–ª–∏—Å—Ç–∞
            checklist = self.validator.generate_checklist_text()

            # –û—Ü–µ–Ω–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
            total_chars = sum(len(article.text) for article in articles)
            estimated_tokens = total_chars // 2  # –î–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ ~2 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω

            # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏: Gemini –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤, Claude –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö/–º–∞–ª—ã—Ö
            # –ö–∞–∫ —É–∫–∞–∑–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: Gemini –±–µ—Ä–µ—Ç –±–æ–ª—å—à–∏–µ —Ç–µ–∫—Å—Ç—ã, Claude "—Ä–∞—Å–∫–ª–∞–¥—ã–≤–∞–µ—Ç –ø–æ –ø–æ–ª–æ—á–∫–∞–º"
            if estimated_tokens > 50_000:
                # –ë–æ–ª—å—à–æ–π –æ–±—ä–µ–º (>50K —Ç–æ–∫–µ–Ω–æ–≤) - –∏—Å–ø–æ–ª—å–∑—É–µ–º Gemini
                pipeline_stage = "document_processing"
                self.logger.info(f"–ë–æ–ª—å—à–æ–π –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö ({estimated_tokens} —Ç–æ–∫–µ–Ω–æ–≤) - –∏—Å–ø–æ–ª—å–∑—É–µ–º Gemini –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            else:
                # –°—Ä–µ–¥–Ω–∏–π/–º–∞–ª—ã–π –æ–±—ä–µ–º - –∏—Å–ø–æ–ª—å–∑—É–µ–º Claude –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
                pipeline_stage = "analysis"
                self.logger.info(f"–£–º–µ—Ä–µ–Ω–Ω—ã–π –æ–±—ä–µ–º –¥–∞–Ω–Ω—ã—Ö ({estimated_tokens} —Ç–æ–∫–µ–Ω–æ–≤) - –∏—Å–ø–æ–ª—å–∑—É–µ–º Claude –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")

            model = self.model_router.select_model_for_pipeline_stage(pipeline_stage)

            # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –∞–≥–µ–Ω—Ç–∞: ReAct (–∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π) –∏–ª–∏ Batch (–ø—Ä–æ—Å—Ç–æ–π)
            if self.use_react_agents:
                # ReAct –∞–≥–µ–Ω—Ç—ã - –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ –º—ã—à–ª–µ–Ω–∏–µ —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏
                react_agent_map = {
                    "constitutionality": ConstitutionalityReActAgent,
                    # TODO: –î–æ–±–∞–≤–∏—Ç—å ReAct –≤–µ—Ä—Å–∏–∏ –¥–ª—è –¥—Ä—É–≥–∏—Ö —ç—Ç–∞–ø–æ–≤
                    # "relevance": RelevanceReActAgent,
                    # "system_integration": SystemIntegrationReActAgent,
                }

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ ReAct –≤–µ—Ä—Å–∏—è –¥–ª—è —ç—Ç–æ–≥–æ —ç—Ç–∞–ø–∞
                if stage_key in react_agent_map:
                    agent_class = react_agent_map[stage_key]
                    agent = agent_class(model)
                    self.logger.info(f"üß† –ó–∞–ø—É—Å–∫ ReAct –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —ç—Ç–∞–ø–∞ '{stage_name}'")
                    self.logger.info(f"   –ú–æ–¥–µ–ª—å: {model.model_name}")
                    self.logger.info(f"   –°—Ç–∞—Ç–µ–π: {len(articles)}")
                    self.logger.info(f"   –†–µ–∂–∏–º: –ê–í–¢–û–ù–û–ú–ù–´–ô (–ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫, deep research)")
                else:
                    # Fallback –Ω–∞ batch –∞–≥–µ–Ω—Ç–∞ –µ—Å–ª–∏ ReAct –≤–µ—Ä—Å–∏–∏ –Ω–µ—Ç
                    self.logger.warning(f"‚ö†Ô∏è ReAct –≤–µ—Ä—Å–∏—è –¥–ª—è '{stage_key}' –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º Batch –∞–≥–µ–Ω—Ç–∞")
                    batch_agent_map = {
                        "relevance": RelevanceFilterAgent,
                        "constitutionality": ConstitutionalityFilterAgent,
                        "system_integration": SystemIntegrationFilterAgent,
                        "legal_technical": LegalTechnicalExpertAgent,
                        "anti_corruption": AntiCorruptionExpertAgent,
                        "gender": GenderExpertAgent
                    }
                    agent_class = batch_agent_map.get(stage_key)
                    if not agent_class:
                        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —ç—Ç–∞–ø–∞: {stage_key}")
                    agent = agent_class(model)
                    self.logger.info(f"üì¶ –ó–∞–ø—É—Å–∫ Batch –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —ç—Ç–∞–ø–∞ '{stage_name}'")
                    self.logger.info(f"   –ú–æ–¥–µ–ª—å: {model.model_name}, –°—Ç–∞—Ç–µ–π: {len(articles)}")
            else:
                # –°—Ç–∞—Ä—ã–µ batch –∞–≥–µ–Ω—Ç—ã (–ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç–∏–Ω–≥)
                batch_agent_map = {
                    "relevance": RelevanceFilterAgent,
                    "constitutionality": ConstitutionalityFilterAgent,
                    "system_integration": SystemIntegrationFilterAgent,
                    "legal_technical": LegalTechnicalExpertAgent,
                    "anti_corruption": AntiCorruptionExpertAgent,
                    "gender": GenderExpertAgent
                }

                agent_class = batch_agent_map.get(stage_key)
                if not agent_class:
                    raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —ç—Ç–∞–ø–∞: {stage_key}")

                agent = agent_class(model)
                self.logger.info(f"üì¶ –ó–∞–ø—É—Å–∫ Batch –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —ç—Ç–∞–ø–∞ '{stage_name}'")
                self.logger.info(f"   –ú–æ–¥–µ–ª—å: {model.model_name}, –°—Ç–∞—Ç–µ–π: {len(articles)}")

            # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ (ReAct –∏–ª–∏ Batch)
            results = agent.analyze_batch(articles, checklist)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            successful_analyses = [r for r in results if r.get('success', False)]
            failed_analyses = [r for r in results if not r.get('success', False)]

            # –ü–æ–º–µ—á–∞–µ–º –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –≤ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–µ
            for result in successful_analyses:
                self.validator.mark_analyzed(
                    result['fragment_number'],
                    result
                )

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∏ –ø—Ä–æ–±–ª–µ–º—ã –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
            recommendations = []
            issues_count = 0

            for result in successful_analyses:
                analysis_text = result.get('analysis', '')

                # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Å—á–µ—Ç –ø—Ä–æ–±–ª–µ–º/—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–æ–º)
                if '–ø—Ä–æ–±–ª–µ–º' in analysis_text.lower() or 'issue' in analysis_text.lower():
                    issues_count += 1

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –∫–∞–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
                if analysis_text:
                    summary = analysis_text[:200] + "..." if len(analysis_text) > 200 else analysis_text
                    recommendations.append(f"–°—Ç–∞—Ç—å—è {result['fragment_number']}: {summary}")

            # –ï—Å–ª–∏ –∞–Ω–∞–ª–∏–∑–æ–≤ –Ω–µ –±—ã–ª–æ, –¥–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
            if not recommendations:
                recommendations.append(f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(successful_analyses)} —Å—Ç–∞—Ç–µ–π")

            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —ç—Ç–∞–ø–∞
            if len(failed_analyses) > 0:
                status = "warning"
            elif issues_count > 0:
                status = "warning"
            else:
                status = "success"

            self.logger.info(f"–≠—Ç–∞–ø '{stage_name}' –∑–∞–≤–µ—Ä—à–µ–Ω: {len(successful_analyses)}/{len(articles)} —É—Å–ø–µ—à–Ω–æ")

            return StageResult(
                stage_name=stage_name,
                stage_number=stage_number,
                status=status,
                articles_analyzed=len(successful_analyses),
                issues_found=issues_count,
                recommendations=recommendations[:5],  # –ü–µ—Ä–≤—ã–µ 5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                detailed_results={
                    "stage_key": stage_key,
                    "options_used": options,
                    "successful_count": len(successful_analyses),
                    "failed_count": len(failed_analyses),
                    "all_results": results  # –ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
                },
                processing_time=0.0  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–∑–∂–µ
            )

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–∞–ø–∞ {stage_name}: {e}")
            import traceback
            self.logger.error(traceback.format_exc())

            return StageResult(
                stage_name=stage_name,
                stage_number=stage_number,
                status="error",
                articles_analyzed=0,
                issues_found=0,
                recommendations=[f"–û—à–∏–±–∫–∞: {str(e)}"],
                detailed_results={"error": str(e), "traceback": traceback.format_exc()},
                processing_time=0.0
            )

    def _stage_result_to_dict(self, result: StageResult) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —ç—Ç–∞–ø–∞ –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return {
            "stage_name": result.stage_name,
            "stage_number": result.stage_number,
            "status": result.status,
            "articles_analyzed": result.articles_analyzed,
            "issues_found": result.issues_found,
            "recommendations": result.recommendations,
            "detailed_results": result.detailed_results,
            "processing_time": result.processing_time
        }

    def export_results_json(self, results: Dict[str, Any]) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON.

        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã

        Returns:
            JSON —Å—Ç—Ä–æ–∫–∞
        """
        return json.dumps(results, ensure_ascii=False, indent=2)

    def export_results_text(self, results: Dict[str, Any]) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç.

        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã

        Returns:
            –¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        """
        if not results.get("success"):
            return f"–û—à–∏–±–∫–∞: {results.get('error')}"

        lines = []
        lines.append("=" * 80)
        lines.append("–û–¢–ß–ï–¢ –û –ü–†–ê–í–û–í–û–ô –≠–ö–°–ü–ï–†–¢–ò–ó–ï –ù–ü–ê –†–ö")
        lines.append("=" * 80)
        lines.append("")

        # –î–æ–∫—É–º–µ–Ω—Ç
        doc = results.get("document", {})
        lines.append(f"–î–æ–∫—É–º–µ–Ω—Ç: {doc.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}")
        lines.append(f"–ù–æ–º–µ—Ä: {doc.get('number', '–ù–µ —É–∫–∞–∑–∞–Ω')}")
        lines.append(f"–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {results.get('timestamp', '')}")
        lines.append("")

        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞
        parsing = results.get("parsing", {})
        lines.append("–°–¢–†–£–ö–¢–£–†–ê –î–û–ö–£–ú–ï–ù–¢–ê:")
        lines.append(f"  –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {parsing.get('fragments_count', 0)}")
        lines.append(f"  –°—Ç–∞—Ç–µ–π: {parsing.get('articles_count', 0)}")
        lines.append(f"  –ì–ª–∞–≤: {parsing.get('chapters_count', 0)}")
        lines.append("")

        # –≠—Ç–∞–ø—ã
        lines.append("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –≠–¢–ê–ü–û–í –≠–ö–°–ü–ï–†–¢–ò–ó–´:")
        lines.append("-" * 80)

        for stage in results.get("stage_results", []):
            icon = "‚úÖ" if stage["status"] == "success" else "‚ö†Ô∏è"
            lines.append(f"{icon} –≠—Ç–∞–ø {stage['stage_number']}: {stage['stage_name']}")
            lines.append(f"   –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å—Ç–∞—Ç–µ–π: {stage['articles_analyzed']}")
            lines.append(f"   –ù–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {stage['issues_found']}")

            if stage["recommendations"]:
                lines.append("   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
                for rec in stage["recommendations"]:
                    lines.append(f"     - {rec}")

            lines.append(f"   –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {stage['processing_time']:.2f} —Å–µ–∫")
            lines.append("")

        # –ü–æ–ª–Ω–æ—Ç–∞
        completeness = results.get("completeness", {})
        lines.append("–ü–û–õ–ù–û–¢–ê –ê–ù–ê–õ–ò–ó–ê:")
        lines.append(f"  –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å—Ç–∞—Ç–µ–π: {completeness.get('analyzed_articles', 0)}/{completeness.get('total_articles', 0)}")
        lines.append(f"  –ü—Ä–æ—Ü–µ–Ω—Ç –ø–æ–ª–Ω–æ—Ç—ã: {completeness.get('completion_rate', 0):.1f}%")
        lines.append("")

        # –ò—Ç–æ–≥–æ
        overall = results.get("overall", {})
        lines.append("=" * 80)
        lines.append("–ò–¢–û–ì–û–í–û–ï –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï")
        lines.append("=" * 80)
        lines.append(f"–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞: {overall.get('quality_score', 0)}/100")
        lines.append(f"–í—Å–µ–≥–æ –ø—Ä–æ–±–ª–µ–º: {overall.get('total_issues', 0)}")
        lines.append(f"–í–µ—Ä–¥–∏–∫—Ç: {overall.get('verdict', '')}")
        lines.append(f"–ì–æ—Ç–æ–≤ –∫ –ø—Ä–∏–Ω—è—Ç–∏—é: {'–î–∞' if overall.get('ready_for_approval') else '–ù–µ—Ç'}")
        lines.append(f"–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {overall.get('processing_time', 0):.2f} —Å–µ–∫")
        lines.append("")
        lines.append("=" * 80)

        return "\n".join(lines)


# Singleton instance –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ web-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
_controller_instance: Optional[WebExpertiseController] = None


def get_controller(use_react_agents: bool = True) -> WebExpertiseController:
    """
    –ü–æ–ª—É—á–∏—Ç—å singleton instance –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–∞.

    Args:
        use_react_agents: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ReAct –∞–≥–µ–Ω—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)

    Returns:
        Instance WebExpertiseController
    """
    global _controller_instance

    if _controller_instance is None:
        _controller_instance = WebExpertiseController(use_react_agents=use_react_agents)

    return _controller_instance
