"""
Legal Expertise Pipeline - –≥–ª–∞–≤–Ω—ã–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –ø—Ä–∞–≤–æ–≤–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –ù–ü–ê.

–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç 6 —Ç–∏–ø–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π –ø–æ–ª–Ω–æ—Ç—ã –∞–Ω–∞–ª–∏–∑–∞.
"""

from typing import Dict, Any, List, Optional
from datetime import datetime
import logging

from legaltechkz.expertise.document_parser import NPADocumentParser, DocumentFragment
from legaltechkz.expertise.completeness_validator import CompletenessValidator
from legaltechkz.expertise.expert_agents import (
    RelevanceFilterAgent,
    ConstitutionalityFilterAgent,
    SystemIntegrationFilterAgent,
    LegalTechnicalExpertAgent,
    AntiCorruptionExpertAgent,
    GenderExpertAgent
)
from legaltechkz.models.model_router import ModelRouter

logger = logging.getLogger("legaltechkz.expertise.pipeline")


class LegalExpertisePipeline:
    """
    –ì–ª–∞–≤–Ω—ã–π pipeline –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –ø—Ä–∞–≤–æ–≤–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –ù–ü–ê.

    –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–≤–æ–¥–∏—Ç 6 —Ç–∏–ø–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
    –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π —Ç—Ä—ë—Ö –º–æ–¥–µ–ª–µ–π:
    - Gemini 2.5 Flash: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    - Claude Sonnet 4.5: –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑
    - GPT-4.1: —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """

    EXPERTISE_STAGES = [
        "–§–∏–ª—å—Ç—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏",
        "–§–∏–ª—å—Ç—Ä –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏",
        "–§–∏–ª—å—Ç—Ä –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏",
        "–Æ—Ä–∏–¥–∏–∫–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞",
        "–ê–Ω—Ç–∏–∫–æ—Ä—Ä—É–ø—Ü–∏–æ–Ω–Ω–∞—è –≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞",
        "–ì–µ–Ω–¥–µ—Ä–Ω–∞—è –≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞"
    ]

    def __init__(self, model_router: Optional[ModelRouter] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pipeline.

        Args:
            model_router: –†–æ—É—Ç–µ—Ä –º–æ–¥–µ–ª–µ–π. –°–æ–∑–¥–∞—ë—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω.
        """
        self.model_router = model_router or ModelRouter(enable_auto_selection=True)
        self.parser = NPADocumentParser()
        self.validator: Optional[CompletenessValidator] = None

        # –ò—Å—Ç–æ—Ä–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        self.execution_history: List[Dict[str, Any]] = []

        logger.info("LegalExpertisePipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def conduct_full_expertise(
        self,
        document_text: str,
        skip_stages: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        –ü—Ä–æ–≤–µ—Å—Ç–∏ –ø–æ–ª–Ω—É—é –ø—Ä–∞–≤–æ–≤—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –¥–æ–∫—É–º–µ–Ω—Ç–∞.

        Args:
            document_text: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –ù–ü–ê.
            skip_stages: –°–ø–∏—Å–æ–∫ —ç—Ç–∞–ø–æ–≤ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ).

        Returns:
            –ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –æ–± —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–µ.
        """
        skip_stages = skip_stages or []

        logger.info("=" * 70)
        logger.info("–ù–ê–ß–ê–õ–û –ö–û–ú–ü–õ–ï–ö–°–ù–û–ô –ü–†–ê–í–û–í–û–ô –≠–ö–°–ü–ï–†–¢–ò–ó–´ –ù–ü–ê")
        logger.info("=" * 70)

        execution_record = {
            'start_time': datetime.now().isoformat(),
            'stages': [],
            'success': True
        }

        try:
            # ==== –®–ê–ì 0: –ü–∞—Ä—Å–∏–Ω–≥ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —á–µ–∫–ª–∏—Å—Ç–∞ ====
            logger.info("\n[–®–ê–ì 0] –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è-—á–µ–∫–ª–∏—Å—Ç–∞...")

            fragments = self.parser.parse(document_text)
            self.validator = CompletenessValidator(fragments)

            checklist_text = self.validator.generate_checklist_text()
            articles = self.parser.get_articles()

            logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Ä–∞–∑–æ–±—Ä–∞–Ω. –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π: {len(articles)}")
            logger.info(f"\n–û–ì–õ–ê–í–õ–ï–ù–ò–ï:\n{checklist_text}\n")

            execution_record['parsing'] = {
                'total_fragments': len(fragments),
                'total_articles': len(articles),
                'success': True
            }

            # ==== –û–°–ù–û–í–ù–´–ï –≠–¢–ê–ü–´ –≠–ö–°–ü–ï–†–¢–ò–ó–´ ====

            # –≠—Ç–∞–ø 1: –§–∏–ª—å—Ç—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (Claude)
            if "–§–∏–ª—å—Ç—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏" not in skip_stages:
                logger.info("\n" + "=" * 70)
                logger.info("[–≠–¢–ê–ü 1] –§–ò–õ–¨–¢–† –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò")
                logger.info("=" * 70)

                model = self.model_router.select_model_for_pipeline_stage("analysis")
                agent = RelevanceFilterAgent(model)

                stage_result = self._run_expertise_stage(agent, articles, checklist_text)
                execution_record['stages'].append(stage_result)

            # –≠—Ç–∞–ø 2: –§–∏–ª—å—Ç—Ä –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏ (Claude)
            if "–§–∏–ª—å—Ç—Ä –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏" not in skip_stages:
                logger.info("\n" + "=" * 70)
                logger.info("[–≠–¢–ê–ü 2] –§–ò–õ–¨–¢–† –ö–û–ù–°–¢–ò–¢–£–¶–ò–û–ù–ù–û–°–¢–ò")
                logger.info("=" * 70)

                model = self.model_router.select_model_for_pipeline_stage("analysis")
                agent = ConstitutionalityFilterAgent(model)

                stage_result = self._run_expertise_stage(agent, articles, checklist_text)
                execution_record['stages'].append(stage_result)

            # –≠—Ç–∞–ø 3: –§–∏–ª—å—Ç—Ä –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ (Claude)
            if "–§–∏–ª—å—Ç—Ä –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏" not in skip_stages:
                logger.info("\n" + "=" * 70)
                logger.info("[–≠–¢–ê–ü 3] –§–ò–õ–¨–¢–† –°–ò–°–¢–ï–ú–ù–û–ô –ò–ù–¢–ï–ì–†–ê–¶–ò–ò")
                logger.info("=" * 70)

                model = self.model_router.select_model_for_pipeline_stage("analysis")
                agent = SystemIntegrationFilterAgent(model)

                stage_result = self._run_expertise_stage(agent, articles, checklist_text)
                execution_record['stages'].append(stage_result)

            # –≠—Ç–∞–ø 4: –Æ—Ä–∏–¥–∏–∫–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ (Claude)
            if "–Æ—Ä–∏–¥–∏–∫–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞" not in skip_stages:
                logger.info("\n" + "=" * 70)
                logger.info("[–≠–¢–ê–ü 4] –Æ–†–ò–î–ò–ö–û-–¢–ï–•–ù–ò–ß–ï–°–ö–ê–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê")
                logger.info("=" * 70)

                model = self.model_router.select_model_for_pipeline_stage("analysis")
                agent = LegalTechnicalExpertAgent(model)

                stage_result = self._run_expertise_stage(agent, articles, checklist_text)
                execution_record['stages'].append(stage_result)

            # –≠—Ç–∞–ø 5: –ê–Ω—Ç–∏–∫–æ—Ä—Ä—É–ø—Ü–∏–æ–Ω–Ω–∞—è –≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ (Claude)
            if "–ê–Ω—Ç–∏–∫–æ—Ä—Ä—É–ø—Ü–∏–æ–Ω–Ω–∞—è –≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞" not in skip_stages:
                logger.info("\n" + "=" * 70)
                logger.info("[–≠–¢–ê–ü 5] –ê–ù–¢–ò–ö–û–†–†–£–ü–¶–ò–û–ù–ù–ê–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê")
                logger.info("=" * 70)

                model = self.model_router.select_model_for_pipeline_stage("analysis")
                agent = AntiCorruptionExpertAgent(model)

                stage_result = self._run_expertise_stage(agent, articles, checklist_text)
                execution_record['stages'].append(stage_result)

            # –≠—Ç–∞–ø 6: –ì–µ–Ω–¥–µ—Ä–Ω–∞—è –≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ (Claude)
            if "–ì–µ–Ω–¥–µ—Ä–Ω–∞—è –≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞" not in skip_stages:
                logger.info("\n" + "=" * 70)
                logger.info("[–≠–¢–ê–ü 6] –ì–ï–ù–î–ï–†–ù–ê–Ø –≠–ö–°–ü–ï–†–¢–ò–ó–ê")
                logger.info("=" * 70)

                model = self.model_router.select_model_for_pipeline_stage("analysis")
                agent = GenderExpertAgent(model)

                stage_result = self._run_expertise_stage(agent, articles, checklist_text)
                execution_record['stages'].append(stage_result)

            # ==== –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –ü–û–õ–ù–û–¢–´ ====
            logger.info("\n" + "=" * 70)
            logger.info("[–§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê] –ü–û–õ–ù–û–¢–ê –ê–ù–ê–õ–ò–ó–ê")
            logger.info("=" * 70)

            completeness_report = self.validator.validate_and_report()
            execution_record['completeness'] = completeness_report

            if not completeness_report['is_complete']:
                logger.error(f"\n‚ö†Ô∏è {completeness_report['recommendation']}")

                # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π
                missing_articles = self.validator.get_missing_articles()

                if missing_articles:
                    logger.warning(f"\nüîÑ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(missing_articles)} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π...")
                    # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É

            else:
                logger.info(f"\n‚úÖ {completeness_report['recommendation']}")

            execution_record['end_time'] = datetime.now().isoformat()

            # ==== –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò–¢–û–ì–û–í–û–ì–û –û–¢–ß–Å–¢–ê ====
            logger.info("\n" + "=" * 70)
            logger.info("[–ó–ê–í–ï–†–®–ï–ù–ò–ï] –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò–¢–û–ì–û–í–û–ì–û –û–¢–ß–Å–¢–ê")
            logger.info("=" * 70)

            final_report = self._generate_final_report(execution_record)

            self.execution_history.append(execution_record)

            logger.info("\n‚úÖ –≠–ö–°–ü–ï–†–¢–ò–ó–ê –ó–ê–í–ï–†–®–ï–ù–ê")
            logger.info("=" * 70)

            return final_report

        except Exception as e:
            logger.error(f"\n‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ü–†–ò –≠–ö–°–ü–ï–†–¢–ò–ó–ï: {e}")
            import traceback
            traceback.print_exc()

            execution_record['success'] = False
            execution_record['error'] = str(e)
            execution_record['end_time'] = datetime.now().isoformat()

            return {
                'success': False,
                'error': str(e),
                'execution_record': execution_record
            }

    def _run_expertise_stage(
        self,
        agent,
        articles: List[DocumentFragment],
        checklist: str
    ) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–¥–∏–Ω —ç—Ç–∞–ø —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã.

        Args:
            agent: –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –∞–≥–µ–Ω—Ç.
            articles: –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.
            checklist: –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ-—á–µ–∫–ª–∏—Å—Ç.

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —ç—Ç–∞–ø–∞.
        """
        stage_start = datetime.now()

        try:
            results = agent.analyze_batch(articles, checklist)

            # –ü–æ–º–µ—á–∞–µ–º –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
            for result in results:
                if result.get('success'):
                    self.validator.mark_analyzed(
                        result['fragment_number'],
                        result
                    )

            stage_summary = agent.get_results_summary()

            stage_duration = (datetime.now() - stage_start).total_seconds()

            logger.info(f"\n‚úÖ –≠—Ç–∞–ø '{agent.agent_name}' –∑–∞–≤–µ—Ä—à—ë–Ω")
            logger.info(f"   –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {stage_summary['successful']}/{stage_summary['total_analyzed']}")
            logger.info(f"   –í—Ä–µ–º—è: {stage_duration:.1f}—Å")

            return {
                'stage_name': agent.agent_name,
                'success': True,
                'summary': stage_summary,
                'results': results,
                'duration_seconds': stage_duration
            }

        except Exception as e:
            logger.error(f"\n‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ '{agent.agent_name}': {e}")

            return {
                'stage_name': agent.agent_name,
                'success': False,
                'error': str(e)
            }

    def _generate_final_report(self, execution_record: Dict[str, Any]) -> Dict[str, Any]:
        """
        –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã.

        Args:
            execution_record: –ó–∞–ø–∏—Å—å –æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏.

        Returns:
            –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç.
        """
        logger.info("\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞...")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT-4.1 –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        model = self.model_router.select_model_for_pipeline_stage("summarization")

        # –°–æ–±–∏—Ä–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –Ω–∞—Ö–æ–¥–∫–∏
        all_findings = []

        for stage in execution_record.get('stages', []):
            if stage.get('success'):
                stage_name = stage['stage_name']
                results = stage.get('results', [])

                for result in results:
                    if result.get('success'):
                        all_findings.append({
                            'stage': stage_name,
                            'article': result['fragment_number'],
                            'analysis': result['analysis']
                        })

        report = {
            'success': execution_record['success'],
            'start_time': execution_record['start_time'],
            'end_time': execution_record['end_time'],
            'parsing': execution_record.get('parsing', {}),
            'stages_completed': len(execution_record.get('stages', [])),
            'completeness': execution_record.get('completeness', {}),
            'total_articles_analyzed': len(all_findings),
            'findings': all_findings,
            'execution_record': execution_record
        }

        logger.info("‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω")

        return report
