# –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –¥–ª—è LegalTechKZ

–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ batch/streaming –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π GPT-4.1, Claude Sonnet 4.5 –∏ Gemini 2.5 Flash –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã –ø—Ä–∞–≤–æ–≤–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã.

## –û–±–∑–æ—Ä –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –ø–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º

### OpenAI GPT-4.1

#### Batch API
- **–°–∫–∏–¥–∫–∞:** 50% –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π —Ü–µ–Ω—ã
- **–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:** –î–æ 24 —á–∞—Å–æ–≤
- **–§–æ—Ä–º–∞—Ç:** JSONL —Ñ–∞–π–ª—ã (–¥–æ 100MB, 50,000 –∑–∞–ø—Ä–æ—Å–æ–≤)
- **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:**
  - –ù–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫–∏ streaming
  - –ù–µ —Å–æ–≤–º–µ—Å—Ç–∏–º —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –≤—ã–∑–æ–≤–∞–º–∏ —Ñ—É–Ω–∫—Ü–∏–π
- **–ö–≤–æ—Ç—ã:** –û—Ç–¥–µ–ª—å–Ω–∞—è, –≤ 2 —Ä–∞–∑–∞ –≤—ã—à–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ API

**–û—Ü–µ–Ω–∫–∞ –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)
- –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ù–ü–ê –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
- –≠–∫–æ–Ω–æ–º–∏—è 50% –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∞—Ä—Ö–∏–≤–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

#### Structured Outputs
- **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å:** 100% –≥–∞—Ä–∞–Ω—Ç–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è JSON —Å—Ö–µ–º–µ
- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞:** –í—Å–µ –º–æ–¥–µ–ª–∏ GPT-4.1+
- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤–∞–ª–∏–¥–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç—á–µ—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã

**–û—Ü–µ–Ω–∫–∞:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ** –¥–ª—è –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã
- –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±–µ–∑ –æ—à–∏–±–æ–∫
- –ò—Å–∫–ª—é—á–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º JSON

#### Function Calling
- **Strict Mode:** –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ö–µ–º–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- **Parallel Calls:** –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤—ã–∑–æ–≤—ã —Ñ—É–Ω–∫—Ü–∏–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ

**–û—Ü–µ–Ω–∫–∞:** ‚≠ê‚≠ê‚≠ê (3/5)
- –ü–æ–ª–µ–∑–Ω–æ, –Ω–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —Ç–µ–∫—É—â–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

### Anthropic Claude Sonnet 4.5

#### Prompt Caching
- **–≠–∫–æ–Ω–æ–º–∏—è:** –î–æ 90% —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–∞ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –ø—Ä–æ–º–ø—Ç–∞—Ö
- **TTL:** 5 –º–∏–Ω—É—Ç (default) –∏–ª–∏ 1 —á–∞—Å (ephemeral)
- **–ú–∏–Ω–∏–º—É–º:** 1024 —Ç–æ–∫–µ–Ω–∞ –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
- **–¶–µ–Ω–∞ –∫–µ—à–∞:** $3.75 –∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞–ø–∏—Å–∏, $0.30 –∑–∞ —á—Ç–µ–Ω–∏–µ
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å:** –†–∞–±–æ—Ç–∞–µ—Ç —Å batch API (–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å–∫–∏–¥–∫–∞)

**–û—Ü–µ–Ω–∫–∞ –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤—ã–≥–æ–¥–∞** –¥–ª—è –Ω–∞—à–µ–π —Å–∏—Å—Ç–µ–º—ã!
- 6 —ç—Ç–∞–ø–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ø–æ—Ö–æ–∂–∏–µ system prompts
- –ü—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ 100 —Å—Ç–∞—Ç–µ–π –æ–¥–Ω–æ–≥–æ –ù–ü–ê:
  - –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤: –ø–æ–ª–Ω–∞—è —Ü–µ–Ω–∞
  - –°–ª–µ–¥—É—é—â–∏–µ 99 –≤—ã–∑–æ–≤–æ–≤: -90% –Ω–∞ system prompt
- **–†–∞—Å—á–µ—Ç —ç–∫–æ–Ω–æ–º–∏–∏:**
  - System prompt: ~2000 —Ç–æ–∫–µ–Ω–æ–≤
  - –ë–µ–∑ –∫–µ—à–∞: 100 –≤—ã–∑–æ–≤–æ–≤ √ó 2000 —Ç–æ–∫–µ–Ω–æ–≤ √ó $3/M = $0.60
  - –° –∫–µ—à–µ–º: 1 –∑–∞–ø–∏—Å—å + 99 —á—Ç–µ–Ω–∏–π = $0.0075 + $0.059 = $0.067
  - **–≠–∫–æ–Ω–æ–º–∏—è: $0.53 (88%) —Ç–æ–ª—å–∫–æ –Ω–∞ system prompts**

#### Extended Thinking Mode
- **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å:** –í–∏–¥–∏–º–æ–µ –ø–æ—à–∞–≥–æ–≤–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
- **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** 96.2% –Ω–∞ MATH 500 (vs 78% –±–µ–∑ thinking)
- **–ë—é–¥–∂–µ—Ç –º—ã—à–ª–µ–Ω–∏—è:** –î–æ 10K —Ç–æ–∫–µ–Ω–æ–≤ –¥—É–º–∞–Ω–∏—è
- **–¶–µ–Ω–∞:** –¢–∞ –∂–µ —á—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π API ($3/$15 –∑–∞ –º–∏–ª–ª–∏–æ–Ω)
- **–í—ã–≤–æ–¥:** –ú—ã—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã –≤ output tokens

**–û—Ü–µ–Ω–∫–∞:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- **–ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è —Å–ª–æ–∂–Ω–æ–≥–æ –ø—Ä–∞–≤–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞**
- –û—Å–æ–±–µ–Ω–Ω–æ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è:
  - –§–∏–ª—å—Ç—Ä –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏ (—Å–ª–æ–∂–Ω—ã–µ NLI —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è)
  - –§–∏–ª—å—Ç—Ä –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ (–≤—ã—è–≤–ª–µ–Ω–∏–µ –∫–æ–ª–ª–∏–∑–∏–π)
  - –ê–Ω—Ç–∏–∫–æ—Ä—Ä—É–ø—Ü–∏–æ–Ω–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ (–ø–æ–∏—Å–∫ —Å–∫—Ä—ã—Ç—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤)
- –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –≤–∞–∂–Ω–∞ –¥–ª—è –ø—Ä–∞–≤–æ–≤—ã—Ö –∑–∞–∫–ª—é—á–µ–Ω–∏–π
- –ú–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å thinking —Ç–æ–∫–µ–Ω—ã –≤ –æ—Ç—á–µ—Ç –∫–∞–∫ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ

#### Batch API (Message Batches)
- **–°–∫–∏–¥–∫–∞:** 50% –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π —Ü–µ–Ω—ã
- **–í—Ä–µ–º—è:** 24 —á–∞—Å–∞
- **–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å:** –†–∞–±–æ—Ç–∞–µ—Ç —Å prompt caching (—Å—É–º–º–∞—Ä–Ω–∞—è —Å–∫–∏–¥–∫–∞!)
- **–§–æ—Ä–º–∞—Ç:** –î–æ 10,000 –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ batch

**–û—Ü–µ–Ω–∫–∞:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)
- –ö–æ–º–±–∏–Ω–∞—Ü–∏—è —Å prompt caching –¥–∞–µ—Ç –æ–≥—Ä–æ–º–Ω—É—é —ç–∫–æ–Ω–æ–º–∏—é
- –ü—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ 10 –ù–ü–ê –≤ batch —Ä–µ–∂–∏–º–µ —Å –∫–µ—à–µ–º:
  - –°–∫–∏–¥–∫–∞ batch: -50%
  - –°–∫–∏–¥–∫–∞ –∫–µ—à: -90% –Ω–∞ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –ø—Ä–æ–º–ø—Ç–∞—Ö
  - **–°—É–º–º–∞—Ä–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏—è: –¥–æ 95%**

#### Interleaved Thinking (Beta)
- **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å:** –î—É–º–∞–Ω–∏–µ –º–µ–∂–¥—É –≤—ã–∑–æ–≤–∞–º–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
- **–°—Ç–∞—Ç—É—Å:** –ó–∞–∫—Ä—ã—Ç–∞—è –±–µ—Ç–∞

**–û—Ü–µ–Ω–∫–∞:** ‚≠ê‚≠ê (2/5)
- –ü–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ —à–∏—Ä–æ–∫–æ, —Å–ª–µ–¥–∏—Ç—å –∑–∞ —Ä–µ–ª–∏–∑–æ–º

### Google Gemini 2.5 Flash

#### Batch API
- **–°–∫–∏–¥–∫–∞:** 50% –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π —Ü–µ–Ω—ã
- **–í—Ä–µ–º—è:** –î–æ 24 —á–∞—Å–æ–≤
- **–§–æ—Ä–º–∞—Ç:** JSONL —Ñ–∞–π–ª—ã (–¥–æ 2GB!)
- **–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å:** –ü–æ–¥–¥–µ—Ä–∂–∫–∞ multimodal –≤ batch

**–û—Ü–µ–Ω–∫–∞:** ‚≠ê‚≠ê‚≠ê‚≠ê (4/5)
- –û—Ç–ª–∏—á–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤
- 2GB –ª–∏–º–∏—Ç –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ—Ç–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

#### Context Caching

**Implicit Caching (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π):**
- –í–∫–ª—é—á–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è Gemini 2.5 Flash
- –ú–∏–Ω–∏–º—É–º: 1024 —Ç–æ–∫–µ–Ω–∞
- TTL: 1 —á–∞—Å
- –¶–µ–Ω–∞: –ë–µ—Å–ø–ª–∞—Ç–Ω–æ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

**Explicit Caching (—Ä—É—á–Ω–æ–π):**
- –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –∫–µ—à–∏—Ä—É–µ–º—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
- TTL: –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π
- –¶–µ–Ω–∞: $0.0001 –∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤ —Ö—Ä–∞–Ω–µ–Ω–∏—è (–≤ —á–∞—Å)

**–û—Ü–µ–Ω–∫–∞:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- **Implicit –∫–µ—à - –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è!**
- –ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏:
  - –ü—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–æ–ª—å—à–æ–≥–æ –ù–ü–ê (500+ —Å—Ç–∞—Ç–µ–π)
  - Gemini –ø–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
  - –°–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∫–µ—à –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- **–ü—Ä–∏–º–µ—Ä:**
  - –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–∫–æ–Ω–∞: 200K —Ç–æ–∫–µ–Ω–æ–≤
  - –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å: –ø–æ–ª–Ω–∞—è —Ü–µ–Ω–∞
  - –°–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã –≤ —Ç–µ—á–µ–Ω–∏–µ —á–∞—Å–∞: 200K —Ç–æ–∫–µ–Ω–æ–≤ –±–µ—Å–ø–ª–∞—Ç–Ω–æ

#### Grounding with Google Search
- **–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å:** –î–æ—Å—Ç—É–ø –∫ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞
- **–†–µ–∂–∏–º—ã:**
  - Dynamic Retrieval: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞
  - Grounding: –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫
- **–ò—Å—Ç–æ—á–Ω–∏–∫–∏:** –ü—Ä–æ–≤–µ—Ä—è–µ–º—ã–µ —Å—Å—ã–ª–∫–∏ –≤ –æ—Ç–≤–µ—Ç–µ
- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞:** –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è, –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö API

**–û—Ü–µ–Ω–∫–∞:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (5/5)
- **–†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–∞–≤–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã!**
- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:
  - –§–∏–ª—å—Ç—Ä –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: –ø–æ–∏—Å–∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –∑–∞–∫–æ–Ω–æ–≤
  - –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–µ–π—Å—Ç–≤—É—é—â–µ–≥–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –†–ö
  - –ü–æ–∏—Å–∫ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–π –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ–≥–æ –°—É–¥–∞
  - –ê–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∞–≤–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏–π
- **–ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞:**
  ```
  "–ü—Ä–æ–≤–µ—Ä—å –∞–∫—Ç—É–∞–ª—å–Ω–∞ –ª–∏ —Ä–µ–¥–∞–∫—Ü–∏—è —Å—Ç–∞—Ç—å–∏ 123 –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏ –†–ö
   –∏ –Ω–∞–π–¥–∏ –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ–≥–æ –°—É–¥–∞ –ø–æ —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ"
  ```
  ‚Üí Gemini –Ω–∞–π–¥–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —Å–∞–π—Ç–æ–≤ adilet.zan.kz, etc.

#### Multimodal Capabilities
- **–§–æ—Ä–º–∞—Ç—ã:** –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, PDF, –≤–∏–¥–µ–æ, –¥–æ–∫—É–º–µ–Ω—Ç—ã
- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –ê–Ω–∞–ª–∏–∑ —Å–∫–∞–Ω–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —Ç–∞–±–ª–∏—Ü, —Å—Ö–µ–º

**–û—Ü–µ–Ω–∫–∞:** ‚≠ê‚≠ê‚≠ê (3/5)
- –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ PDF –≤–µ—Ä—Å–∏–π –ù–ü–ê
- –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏ —Å–∏—Å—Ç–µ–º—ã

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤–Ω–µ–¥—Ä–µ–Ω–∏—é

### 1. Prompt Caching –¥–ª—è Claude (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –í–´–°–û–ö–ò–ô)

**–ß—Ç–æ –¥–µ–ª–∞—Ç—å:**
–í–Ω–µ–¥—Ä–∏—Ç—å prompt caching –¥–ª—è –≤—Å–µ—Ö 6 —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤.

**–ö–∞–∫ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å:**

```python
# legaltechkz/models/anthropic_model.py

def generate(self, prompt: str, system_message: Optional[str] = None,
             use_caching: bool = True, **kwargs) -> str:
    """
    Generate with optional prompt caching support.
    """
    messages = [{"role": "user", "content": prompt}]

    extra_headers = {}
    system_blocks = []

    if use_caching and system_message:
        # Enable caching for system prompt
        extra_headers["anthropic-beta"] = "prompt-caching-2024-07-31"
        system_blocks = [
            {
                "type": "text",
                "text": system_message,
                "cache_control": {"type": "ephemeral"}
            }
        ]
    elif system_message:
        system_blocks = [{"type": "text", "text": system_message}]

    response = self.client.messages.create(
        model=self.model_name,
        max_tokens=self.max_tokens,
        system=system_blocks,
        messages=messages,
        extra_headers=extra_headers,
        **kwargs
    )

    return response.content[0].text
```

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö –∞–≥–µ–Ω—Ç–∞—Ö:**

```python
# legaltechkz/expertise/expert_agents.py

class RelevanceFilterAgent(BaseExpertAgent):
    def analyze_fragment(self, fragment: DocumentFragment,
                        checklist: str) -> Dict[str, Any]:
        system_prompt = self.get_system_prompt()
        analysis_prompt = self.get_analysis_prompt(fragment, checklist)

        # Enable caching for system prompt (same across all articles)
        response = self.model.generate(
            prompt=analysis_prompt,
            system_message=system_prompt,
            use_caching=True  # ‚Üê –≠–∫–æ–Ω–æ–º–∏—è 90% –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –≤—ã–∑–æ–≤–∞—Ö
        )

        return self._parse_response(response)
```

**–û–∂–∏–¥–∞–µ–º–∞—è —ç–∫–æ–Ω–æ–º–∏—è:**
- –ê–Ω–∞–ª–∏–∑ –ù–ü–ê —Å 100 —Å—Ç–∞—Ç—å—è–º–∏
- 6 —ç—Ç–∞–ø–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã
- System prompt: ~2000 —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ —ç—Ç–∞–ø
- **–ë–µ–∑ –∫–µ—à–∞:** 100 √ó 6 √ó 2000 √ó $3/M = $3.60
- **–° –∫–µ—à–µ–º:** 6 √ó ($0.0075 + 99 √ó $0.0006) = $0.40
- **–≠–∫–æ–Ω–æ–º–∏—è: $3.20 (89%) —Ç–æ–ª—å–∫–æ –Ω–∞ system prompts**

### 2. Extended Thinking –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —ç—Ç–∞–ø–æ–≤ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –í–´–°–û–ö–ò–ô)

**–ß—Ç–æ –¥–µ–ª–∞—Ç—å:**
–í–∫–ª—é—á–∏—Ç—å Extended Thinking –¥–ª—è —ç—Ç–∞–ø–æ–≤ —Ç—Ä–µ–±—É—é—â–∏—Ö –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**

```python
# legaltechkz/models/anthropic_model.py

def generate_with_thinking(self, prompt: str,
                          system_message: Optional[str] = None,
                          thinking_budget: int = 10000,
                          use_caching: bool = True) -> Dict[str, Any]:
    """
    Generate with extended thinking mode.

    Returns:
        {
            'response': str,  # Actual response
            'thinking': str   # Thinking process (for transparency)
        }
    """
    extra_headers = {
        "anthropic-beta": "max-tokens-3-5-sonnet-2024-07-15"
    }

    if use_caching:
        extra_headers["anthropic-beta"] += ",prompt-caching-2024-07-31"

    system_blocks = []
    if system_message:
        cache_control = {"type": "ephemeral"} if use_caching else None
        system_blocks = [{
            "type": "text",
            "text": system_message,
            **({"cache_control": cache_control} if cache_control else {})
        }]

    response = self.client.messages.create(
        model=self.model_name,
        max_tokens=thinking_budget + self.max_tokens,
        system=system_blocks,
        messages=[{"role": "user", "content": prompt}],
        thinking={
            "type": "enabled",
            "budget_tokens": thinking_budget
        },
        extra_headers=extra_headers
    )

    # Extract thinking and response
    thinking_text = ""
    response_text = ""

    for block in response.content:
        if block.type == "thinking":
            thinking_text = block.thinking
        elif block.type == "text":
            response_text = block.text

    return {
        'response': response_text,
        'thinking': thinking_text
    }
```

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**

```python
# legaltechkz/expertise/expert_agents.py

class ConstitutionalityFilterAgent(BaseExpertAgent):
    """
    –§–∏–ª—å—Ç—Ä –∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏ - —Ç—Ä–µ–±—É–µ—Ç –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º Extended Thinking –¥–ª—è –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π.
    """

    def analyze_fragment(self, fragment: DocumentFragment,
                        checklist: str) -> Dict[str, Any]:
        system_prompt = self.get_system_prompt()
        analysis_prompt = self.get_analysis_prompt(fragment, checklist)

        # Use extended thinking for complex constitutional analysis
        result = self.model.generate_with_thinking(
            prompt=analysis_prompt,
            system_message=system_prompt,
            thinking_budget=5000,  # –ë—é–¥–∂–µ—Ç –Ω–∞ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è
            use_caching=True
        )

        return {
            'fragment_number': fragment.number,
            'analysis': result['response'],
            'reasoning': result['thinking'],  # –í–∫–ª—é—á–∞–µ–º –≤ –æ—Ç—á–µ—Ç!
            'success': True
        }
```

**–ö–∞–∫–∏–µ —ç—Ç–∞–ø—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç thinking:**
1. ‚úÖ –§–∏–ª—å—Ç—Ä –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏ (NLI –∞–Ω–∞–ª–∏–∑, —Å–ª–æ–∂–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è)
2. ‚úÖ –§–∏–ª—å—Ç—Ä –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ (–ø–æ–∏—Å–∫ –∫–æ–ª–ª–∏–∑–∏–π)
3. ‚úÖ –ê–Ω—Ç–∏–∫–æ—Ä—Ä—É–ø—Ü–∏–æ–Ω–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ (–≤—ã—è–≤–ª–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤)
4. ‚ùå –§–∏–ª—å—Ç—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ (–±–∞–∑–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –Ω–µ –Ω—É–∂–µ–Ω)
5. ‚ùå –Æ—Ä–∏–¥–∏–∫–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è (—Ñ–æ—Ä–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
6. ‚ùå –ì–µ–Ω–¥–µ—Ä–Ω–∞—è (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å: –≤–∏–¥–Ω–æ –∫–∞–∫ –º–æ–¥–µ–ª—å –ø—Ä–∏—à–ª–∞ –∫ –≤—ã–≤–æ–¥—É
- –ö–∞—á–µ—Å—Ç–≤–æ: –ª—É—á—à–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö (+18% –Ω–∞ MATH 500)
- –õ–µ–≥–∞–ª—å–Ω–æ—Å—Ç—å: —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å –≤ –ø—Ä–∞–≤–æ–≤–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –∫–∞–∫ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ

### 3. Grounding –¥–ª—è –∞–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –°–†–ï–î–ù–ò–ô)

**–ß—Ç–æ –¥–µ–ª–∞—Ç—å:**
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Gemini —Å grounding –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞.

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**

```python
# legaltechkz/models/gemini_model.py

def generate_with_grounding(self, prompt: str,
                           dynamic_retrieval: bool = True) -> Dict[str, Any]:
    """
    Generate with Google Search grounding for up-to-date information.

    Args:
        prompt: Query that may benefit from current web information
        dynamic_retrieval: Let model decide when to search (recommended)

    Returns:
        {
            'response': str,
            'grounding_metadata': {
                'search_queries': List[str],
                'grounding_chunks': List[dict],
                'web_search_queries': List[str]
            }
        }
    """
    from google.genai import types

    # Configure grounding
    if dynamic_retrieval:
        # Model decides when to search
        google_search_tool = types.Tool(
            google_search=types.GoogleSearch()
        )
        config = types.GenerateContentConfig(
            tools=[google_search_tool],
            response_modalities=["TEXT"]
        )
    else:
        # Always use grounding
        config = types.GenerateContentConfig(
            grounding=types.GroundingConfig(
                google_search_grounding=types.GoogleSearchGroundingConfig()
            )
        )

    response = self.client.models.generate_content(
        model=self.model_name,
        contents=prompt,
        config=config
    )

    # Extract grounding metadata
    grounding_metadata = {}
    if hasattr(response, 'grounding_metadata'):
        grounding_metadata = {
            'search_queries': response.grounding_metadata.search_entry_point.rendered_content,
            'grounding_chunks': [
                {
                    'web_uri': chunk.web.uri,
                    'web_title': chunk.web.title
                }
                for chunk in response.grounding_metadata.grounding_chunks
            ],
            'web_search_queries': response.grounding_metadata.web_search_queries
        }

    return {
        'response': response.text,
        'grounding_metadata': grounding_metadata
    }
```

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ –§–∏–ª—å—Ç—Ä–µ –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏:**

```python
class SystemIntegrationFilterAgent(BaseExpertAgent):
    """
    –§–∏–ª—å—Ç—Ä —Å–∏—Å—Ç–µ–º–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ - –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–ª–ª–∏–∑–∏–∏ —Å –¥–µ–π—Å—Ç–≤—É—é—â–∏–º –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ–º.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Gemini —Å grounding –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –∑–∞–∫–æ–Ω–æ–≤.
    """

    def __init__(self, model: BaseModel, grounding_model: Optional[GeminiModel] = None):
        super().__init__(model)
        self.grounding_model = grounding_model  # Gemini –¥–ª—è grounding

    def analyze_fragment(self, fragment: DocumentFragment,
                        checklist: str) -> Dict[str, Any]:
        # –®–∞–≥ 1: –û—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Claude
        analysis = super().analyze_fragment(fragment, checklist)

        # –®–∞–≥ 2: –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Å—Å—ã–ª–∫–∏ –Ω–∞ –¥—Ä—É–≥–∏–µ –∑–∞–∫–æ–Ω—ã - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å
        if self.grounding_model and self._has_legal_references(analysis):
            references = self._extract_legal_references(analysis)

            for ref in references:
                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á–µ—Ä–µ–∑ Google Search
                grounding_query = f"""
                –ù–∞–π–¥–∏ –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Ä–µ–¥–∞–∫—Ü–∏—é {ref['law_name']} {ref.get('article', '')}
                –Ω–∞ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–º —Å–∞–π—Ç–µ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω (adilet.zan.kz).
                –£–∫–∞–∂–∏ –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π.
                """

                grounded_result = self.grounding_model.generate_with_grounding(
                    prompt=grounding_query,
                    dynamic_retrieval=True
                )

                # –î–æ–±–∞–≤–∏—Ç—å –≤ –∞–Ω–∞–ª–∏–∑
                analysis['legal_references_verification'] = analysis.get('legal_references_verification', [])
                analysis['legal_references_verification'].append({
                    'reference': ref,
                    'current_version': grounded_result['response'],
                    'sources': grounded_result['grounding_metadata']['grounding_chunks']
                })

        return analysis
```

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**

```
–°—Ç–∞—Ç—å—è –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ –ù–ü–ê —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞:
"–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å–æ —Å—Ç–∞—Ç—å–µ–π 123 –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–≥–æ –∫–æ–¥–µ–∫—Å–∞ –†–ö"

‚Üí Gemini —Å grounding:
  1. –ò—â–µ—Ç –Ω–∞ adilet.zan.kz –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç—å—é 123 –ì–ö –†–ö
  2. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–≥–¥–∞ –±—ã–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
  3. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç + –∏—Å—Ç–æ—á–Ω–∏–∫–∏

‚Üí –í –æ—Ç—á–µ—Ç–µ:
  "–°—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç. 123 –ì–ö –†–ö –∞–∫—Ç—É–∞–ª—å–Ω–∞.
   –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è: 15.03.2024.
   –ò—Å—Ç–æ—á–Ω–∏–∫: https://adilet.zan.kz/rus/docs/K1400000269"
```

### 4. Structured Outputs –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ —Ñ–æ—Ä–º–∞—Ç–∞ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –í–´–°–û–ö–ò–ô)

**–ß—Ç–æ –¥–µ–ª–∞—Ç—å:**
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Structured Outputs OpenAI –¥–ª—è —ç—Ç–∞–ø–æ–≤ –≥–¥–µ –∫—Ä–∏—Ç–∏—á–µ–Ω —Ñ–æ—Ä–º–∞—Ç JSON.

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**

```python
# legaltechkz/models/openai_model.py

from pydantic import BaseModel as PydanticBaseModel
from typing import Type

def generate_structured(self,
                       prompt: str,
                       response_model: Type[PydanticBaseModel],
                       system_message: Optional[str] = None) -> PydanticBaseModel:
    """
    Generate with guaranteed structured output using Pydantic model.

    Args:
        prompt: User prompt
        response_model: Pydantic model class defining the structure
        system_message: Optional system message

    Returns:
        Instance of response_model with parsed data
    """
    messages = []
    if system_message:
        messages.append({"role": "system", "content": system_message})
    messages.append({"role": "user", "content": prompt})

    completion = self.client.beta.chat.completions.parse(
        model=self.model_name,
        messages=messages,
        response_format=response_model,
        temperature=self.temperature
    )

    return completion.choices[0].message.parsed
```

**–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ö–µ–º –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤:**

```python
# legaltechkz/expertise/report_schemas.py

from pydantic import BaseModel, Field
from typing import List, Optional
from enum import Enum

class ConfidenceLevel(str, Enum):
    HIGH = "–≤—ã—Å–æ–∫–∞—è"
    MEDIUM = "—Å—Ä–µ–¥–Ω—è—è"
    LOW = "–Ω–∏–∑–∫–∞—è"

class RelevanceVerdict(str, Enum):
    NORMATIVE = "–ù–æ—Ä–º–∞—Ç–∏–≤–µ–Ω"
    NON_NORMATIVE = "–ù–µ–Ω–æ—Ä–º–∞—Ç–∏–≤–µ–Ω"
    MIXED = "–°–º–µ—à–∞–Ω–Ω—ã–π"

class RelevanceAnalysis(BaseModel):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–Ω–∞–ª–∏–∑–∞ –§–∏–ª—å—Ç—Ä–∞ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏."""

    article_number: str = Field(description="–ù–æ–º–µ—Ä —Å—Ç–∞—Ç—å–∏")
    article_text: str = Field(description="–¢–µ–∫—Å—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–π –Ω–æ—Ä–º—ã")

    # –¢–µ—Å—Ç –Ω–∞ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å
    normativity_test: dict = Field(description="–†–µ–∑—É–ª—å—Ç–∞—Ç—ã 5 —Ç–µ—Å—Ç–æ–≤ –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏")
    normativity_score: float = Field(ge=0, le=1, description="–ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª –Ω–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏")

    # –ú–∞—Ç—Ä–∏—Ü–∞ ILNR
    ilnr_impact: int = Field(ge=1, le=5, description="–í–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ (Impact)")
    ilnr_legality: int = Field(ge=1, le=5, description="–ó–∞–∫–æ–Ω–Ω–æ—Å—Ç—å (Legality)")
    ilnr_necessity: int = Field(ge=1, le=5, description="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å (Necessity)")
    ilnr_rationality: int = Field(ge=1, le=5, description="–†–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (Rationality)")
    ilnr_index: float = Field(description="–ò–Ω–¥–µ–∫—Å ILNR")

    # –í–µ—Ä–¥–∏–∫—Ç
    verdict: RelevanceVerdict
    recommended_level: str = Field(description="–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —É—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∞")

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations: List[str] = Field(description="–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
    confidence: ConfidenceLevel = Field(description="–£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")


class ConstitutionalityAnalysis(BaseModel):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–Ω–∞–ª–∏–∑–∞ –§–∏–ª—å—Ç—Ä–∞ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏."""

    article_number: str
    article_text: str

    # NLI –∞–Ω–∞–ª–∏–∑
    constitutional_nli: dict = Field(description="NLI –∞–Ω–∞–ª–∏–∑ —Å –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–µ–π")
    court_decisions_nli: Optional[dict] = Field(description="NLI —Å –ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è–º–∏ –ö–°")

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    is_constitutional: bool = Field(description="–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏")
    contradictions_found: List[str] = Field(description="–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è")

    recommendations: List[str]
    confidence: ConfidenceLevel


class SystemIntegrationAnalysis(BaseModel):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∞–Ω–∞–ª–∏–∑–∞ –§–∏–ª—å—Ç—Ä–∞ –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏."""

    article_number: str
    article_text: str

    # –ê—É–¥–∏—Ç—ã
    vertical_audit: dict = Field(description="–í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π –∞—É–¥–∏—Ç")
    horizontal_screening: dict = Field(description="–ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–Ω–∏–Ω–≥")
    terminology_control: dict = Field(description="–¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç—Ä–æ–ª—å")

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    conflicts_found: List[dict] = Field(description="–ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–ª–∏–∑–∏–∏")
    terminology_issues: List[str] = Field(description="–¢–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã")

    recommendations: List[str]
    confidence: ConfidenceLevel


class LegalTechnicalAnalysis(BaseModel):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Æ—Ä–∏–¥–∏–∫–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã."""

    article_number: str
    article_text: str

    # –ê–Ω–∞–ª–∏–∑—ã
    legal_technique: dict = Field(description="–û—Ü–µ–Ω–∫–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π —Ç–µ—Ö–Ω–∏–∫–∏")
    linguistic_analysis: dict = Field(description="–õ–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
    logical_assessment: dict = Field(description="–õ–æ–≥–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞")

    issues_found: List[str] = Field(description="–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã")
    recommendations: List[str]
    confidence: ConfidenceLevel


class AntiCorruptionAnalysis(BaseModel):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ê–Ω—Ç–∏–∫–æ—Ä—Ä—É–ø—Ü–∏–æ–Ω–Ω–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã."""

    article_number: str
    article_text: str

    # –§–∞–∫—Ç–æ—Ä—ã
    linguistic_uncertainty: dict = Field(description="–Æ—Ä–∏–¥–∏–∫–æ-–ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å")
    discretion_width: dict = Field(description="–®–∏—Ä–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ü–∏–∏")
    legal_gaps: List[str] = Field(description="–ü—Ä–∞–≤–æ–≤—ã–µ –ø—Ä–æ–±–µ–ª—ã")
    administrative_barriers: List[str] = Field(description="–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–µ –±–∞—Ä—å–µ—Ä—ã")

    # –û—Ü–µ–Ω–∫–∞
    corruption_risk_level: str = Field(description="–£—Ä–æ–≤–µ–Ω—å –∫–æ—Ä—Ä—É–ø—Ü–∏–æ–Ω–Ω–æ–≥–æ —Ä–∏—Å–∫–∞")
    risk_factors_count: int = Field(ge=0, description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–∫—Ç–æ—Ä–æ–≤")

    recommendations: List[str]
    confidence: ConfidenceLevel


class GenderAnalysis(BaseModel):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ì–µ–Ω–¥–µ—Ä–Ω–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã."""

    article_number: str
    article_text: str

    # –ê–Ω–∞–ª–∏–∑—ã
    gender_impact: dict = Field(description="–ì–µ–Ω–¥–µ—Ä–Ω–æ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ")
    discrimination_check: dict = Field(description="–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏–∏")
    stereotype_analysis: dict = Field(description="–ê–Ω–∞–ª–∏–∑ —Å—Ç–µ—Ä–µ–æ—Ç–∏–ø–æ–≤")

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    has_gender_impact: bool = Field(description="–ò–º–µ–µ—Ç –ª–∏ –≥–µ–Ω–¥–µ—Ä–Ω–æ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ")
    issues_found: List[str] = Field(description="–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã")

    recommendations: List[str]
    confidence: ConfidenceLevel
```

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**

```python
# legaltechkz/expertise/legal_expertise_pipeline.py

from legaltechkz.expertise.report_schemas import (
    RelevanceAnalysis,
    ConstitutionalityAnalysis,
    # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ö–µ–º—ã
)

class LegalExpertisePipeline:
    def _run_stage_with_structured_output(self,
                                         stage_name: str,
                                         agent: BaseExpertAgent,
                                         fragment: DocumentFragment,
                                         response_model: Type[PydanticBaseModel]) -> dict:
        """
        –ó–∞–ø—É—Å—Ç–∏—Ç—å —ç—Ç–∞–ø —Å –≥–∞—Ä–∞–Ω—Ç–∏–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞.
        """
        # –î–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º GPT —Å Structured Outputs
        gpt_model = self.model_router._create_model_from_config({
            "provider": "openai",
            "model_name": "gpt-4o-2024-08-06",  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Structured Outputs
            "temperature": 0.1
        })

        # –ü–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ (Claude)
        raw_analysis = agent.analyze_fragment(fragment, checklist)

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —á–µ—Ä–µ–∑ GPT
        conversion_prompt = f"""
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–π —Å–ª–µ–¥—É—é—â–∏–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–∞–≤–æ–≤–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –≤ —Å—Ç—Ä–æ–≥–∏–π JSON —Ñ–æ—Ä–º–∞—Ç.

        –ê–Ω–∞–ª–∏–∑:
        {raw_analysis['analysis']}

        –ò–∑–≤–ª–µ–∫–∏ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ.
        """

        structured_result = gpt_model.generate_structured(
            prompt=conversion_prompt,
            response_model=response_model,
            system_message="–¢—ã –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—à—å –ø—Ä–∞–≤–æ–≤—ã–µ –∞–Ω–∞–ª–∏–∑—ã –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç."
        )

        return structured_result.model_dump()
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- 100% –≥–∞—Ä–∞–Ω—Ç–∏—è –≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ Pydantic
- –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
- –õ–µ–≥–∫–æ –ø–∞—Ä—Å–∏—Ç—å –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### 5. Batch API –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –°–†–ï–î–ù–ò–ô)

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏–≤–∞ –ù–ü–ê (–¥–µ—Å—è—Ç–∫–∏/—Å–æ—Ç–Ω–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
- –ù–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
- –ù–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏

**–†–µ–∞–ª–∏–∑–∞—Ü–∏—è:**

```python
# legaltechkz/batch/batch_processor.py

from typing import List, Dict, Any
import json
from pathlib import Path
import time

class BatchExpertiseProcessor:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ batch —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ù–ü–ê.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Batch API –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ 50%.
    """

    def __init__(self, provider: str = "anthropic"):
        """
        Args:
            provider: "anthropic", "openai", –∏–ª–∏ "google"
        """
        self.provider = provider
        self.model_router = ModelRouter()

    def prepare_batch_file(self,
                          documents: List[Dict[str, str]],
                          output_path: str) -> str:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å JSONL —Ñ–∞–π–ª –¥–ª—è batch –æ–±—Ä–∞–±–æ—Ç–∫–∏.

        Args:
            documents: [{"id": "doc1", "text": "...", "name": "–ó–∞–∫–æ–Ω –æ..."}, ...]
            output_path: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É JSONL —Ñ–∞–π–ª—É

        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        batch_requests = []

        for doc in documents:
            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–ª–Ω—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É
            request = self._create_batch_request(
                custom_id=doc['id'],
                document_text=doc['text'],
                document_name=doc.get('name', doc['id'])
            )
            batch_requests.append(request)

        # –ó–∞–ø–∏—Å–∞—Ç—å –≤ JSONL
        with open(output_path, 'w', encoding='utf-8') as f:
            for req in batch_requests:
                f.write(json.dumps(req, ensure_ascii=False) + '\n')

        return output_path

    def _create_batch_request(self, custom_id: str,
                             document_text: str,
                             document_name: str) -> dict:
        """–°–æ–∑–¥–∞—Ç—å batch –∑–∞–ø—Ä–æ—Å –≤ —Ñ–æ—Ä–º–∞—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""

        if self.provider == "anthropic":
            return {
                "custom_id": custom_id,
                "params": {
                    "model": "claude-sonnet-4-5-20250514",
                    "max_tokens": 16000,
                    "messages": [
                        {
                            "role": "user",
                            "content": f"""
                            –ü—Ä–æ–≤–µ–¥–∏ –ø–æ–ª–Ω—É—é –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –ø—Ä–∞–≤–æ–≤—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É —Å–ª–µ–¥—É—é—â–µ–≥–æ –ù–ü–ê:

                            –ù–∞–∑–≤–∞–Ω–∏–µ: {document_name}

                            –¢–µ–∫—Å—Ç:
                            {document_text}

                            –í—ã–ø–æ–ª–Ω–∏ –≤—Å–µ 6 —ç—Ç–∞–ø–æ–≤:
                            1. –§–∏–ª—å—Ç—Ä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                            2. –§–∏–ª—å—Ç—Ä –ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–Ω–æ—Å—Ç–∏
                            3. –§–∏–ª—å—Ç—Ä –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
                            4. –Æ—Ä–∏–¥–∏–∫–æ-—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞
                            5. –ê–Ω—Ç–∏–∫–æ—Ä—Ä—É–ø—Ü–∏–æ–Ω–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞
                            6. –ì–µ–Ω–¥–µ—Ä–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞

                            –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç–∞—Ç—å–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑.
                            """
                        }
                    ]
                }
            }

        elif self.provider == "openai":
            return {
                "custom_id": custom_id,
                "method": "POST",
                "url": "/v1/chat/completions",
                "body": {
                    "model": "gpt-4.1-2024-08-06",
                    "messages": [
                        {
                            "role": "system",
                            "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–∞–≤–æ–≤–æ–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–µ –ù–ü–ê –†–ö."
                        },
                        {
                            "role": "user",
                            "content": f"–ü—Ä–æ–≤–µ–¥–∏ –ø–æ–ª–Ω—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –ù–ü–ê: {document_name}\n\n{document_text}"
                        }
                    ],
                    "max_tokens": 16000
                }
            }

        # Google Gemini batch format
        else:
            return {
                "request": {
                    "contents": [{
                        "role": "user",
                        "parts": [{
                            "text": f"–≠–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ –ù–ü–ê: {document_name}\n\n{document_text}"
                        }]
                    }]
                },
                "request_id": custom_id
            }

    def submit_batch(self, batch_file_path: str) -> str:
        """
        –û—Ç–ø—Ä–∞–≤–∏—Ç—å batch –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É.

        Returns:
            batch_id –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞
        """
        if self.provider == "anthropic":
            from anthropic import Anthropic
            client = Anthropic()

            with open(batch_file_path, 'rb') as f:
                batch = client.messages.batches.create(
                    requests=f
                )

            return batch.id

        elif self.provider == "openai":
            from openai import OpenAI
            client = OpenAI()

            with open(batch_file_path, 'rb') as f:
                batch_input_file = client.files.create(
                    file=f,
                    purpose="batch"
                )

            batch = client.batches.create(
                input_file_id=batch_input_file.id,
                endpoint="/v1/chat/completions",
                completion_window="24h"
            )

            return batch.id

        else:  # Google
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Files API –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            from google import genai
            client = genai.Client()

            # Upload batch file
            file = client.files.upload(path=batch_file_path)

            # Create batch job
            batch_job = client.batches.create(
                src=file.uri,
                model="gemini-2.5-flash"
            )

            return batch_job.name

    def check_batch_status(self, batch_id: str) -> dict:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å batch –æ–±—Ä–∞–±–æ—Ç–∫–∏."""

        if self.provider == "anthropic":
            from anthropic import Anthropic
            client = Anthropic()
            batch = client.messages.batches.retrieve(batch_id)

            return {
                'status': batch.processing_status,
                'requests_total': batch.request_counts.total,
                'requests_completed': batch.request_counts.succeeded,
                'requests_failed': batch.request_counts.errored
            }

        elif self.provider == "openai":
            from openai import OpenAI
            client = OpenAI()
            batch = client.batches.retrieve(batch_id)

            return {
                'status': batch.status,
                'requests_total': batch.request_counts.total,
                'requests_completed': batch.request_counts.completed,
                'requests_failed': batch.request_counts.failed
            }

        else:  # Google
            from google import genai
            client = genai.Client()
            batch = client.batches.get(name=batch_id)

            return {
                'status': batch.state.name,
                'requests_total': batch.total_requests,
                'requests_completed': batch.processed_requests
            }

    def retrieve_results(self, batch_id: str, output_dir: str) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã batch –æ–±—Ä–∞–±–æ—Ç–∫–∏.

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        Path(output_dir).mkdir(parents=True, exist_ok=True)

        if self.provider == "anthropic":
            from anthropic import Anthropic
            client = Anthropic()

            # –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = []
            for result in client.messages.batches.results(batch_id):
                if result.result.type == "succeeded":
                    results.append({
                        'document_id': result.custom_id,
                        'expertise': result.result.message.content[0].text,
                        'success': True
                    })
                else:
                    results.append({
                        'document_id': result.custom_id,
                        'error': result.result.error,
                        'success': False
                    })

            # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å
            output_file = Path(output_dir) / f"batch_{batch_id}_results.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

            return results

        elif self.provider == "openai":
            from openai import OpenAI
            client = OpenAI()

            batch = client.batches.retrieve(batch_id)

            # –°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if batch.output_file_id:
                file_response = client.files.content(batch.output_file_id)
                output_file = Path(output_dir) / f"batch_{batch_id}_results.jsonl"

                with open(output_file, 'wb') as f:
                    f.write(file_response.content)

                # –ü–∞—Ä—Å–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                results = []
                with open(output_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        result = json.loads(line)
                        results.append({
                            'document_id': result['custom_id'],
                            'expertise': result['response']['body']['choices'][0]['message']['content'],
                            'success': True
                        })

                return results

        else:  # Google
            from google import genai
            client = genai.Client()

            batch = client.batches.get(name=batch_id)

            # –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            output_file_uri = batch.output_uri
            # Download and parse...

            return []  # Implement based on Google's format

    def wait_for_completion(self, batch_id: str,
                           check_interval: int = 60) -> dict:
        """
        –ñ–¥–∞—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è batch –æ–±—Ä–∞–±–æ—Ç–∫–∏.

        Args:
            batch_id: ID batch –∑–∞–¥–∞—á–∏
            check_interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

        Returns:
            –§–∏–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        """
        while True:
            status = self.check_batch_status(batch_id)

            print(f"–°—Ç–∞—Ç—É—Å: {status['status']}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {status['requests_completed']}/{status['requests_total']}")

            if status['status'] in ['completed', 'COMPLETED', 'ended']:
                return status

            time.sleep(check_interval)
```

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**

```python
# examples/batch_expertise_example.py

from legaltechkz.batch.batch_processor import BatchExpertiseProcessor

# –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ù–ü–ê –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
documents = [
    {
        "id": "law_001",
        "name": "–ó–∞–∫–æ–Ω –æ —Ü–∏—Ñ—Ä–æ–≤–∏–∑–∞—Ü–∏–∏ 2024",
        "text": "... –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∑–∞–∫–æ–Ω–∞ ..."
    },
    {
        "id": "law_002",
        "name": "–ü—Ä–æ–µ–∫—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ì–ö –†–ö",
        "text": "... –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç ..."
    },
    # ... –µ—â–µ 98 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
]

# –°–æ–∑–¥–∞—Ç—å batch processor
processor = BatchExpertiseProcessor(provider="anthropic")

# –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å batch —Ñ–∞–π–ª
batch_file = processor.prepare_batch_file(
    documents=documents,
    output_path="batch_requests.jsonl"
)

# –û—Ç–ø—Ä–∞–≤–∏—Ç—å –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É
batch_id = processor.submit_batch(batch_file)
print(f"Batch –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω: {batch_id}")

# –ñ–¥–∞—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
print("–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (–¥–æ 24 —á–∞—Å–æ–≤)...")
status = processor.wait_for_completion(batch_id)

# –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
results = processor.retrieve_results(
    batch_id=batch_id,
    output_dir="batch_results"
)

# –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
for result in results:
    if result['success']:
        print(f"‚úÖ {result['document_id']}: —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç
        with open(f"reports/{result['document_id']}.txt", 'w') as f:
            f.write(result['expertise'])
    else:
        print(f"‚ùå {result['document_id']}: –æ—à–∏–±–∫–∞ - {result['error']}")

print(f"\nüí∞ –≠–∫–æ–Ω–æ–º–∏—è: 50% –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π —Ü–µ–Ω—ã")
print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(results)}")
```

**–≠–∫–æ–Ω–æ–º–∏–∫–∞:**
- 100 –ù–ü–ê √ó —Å—Ä–µ–¥–Ω–µ–µ 50K —Ç–æ–∫–µ–Ω–æ–≤ –∫–∞–∂–¥—ã–π = 5M —Ç–æ–∫–µ–Ω–æ–≤
- Claude —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ: 5M √ó $3/M = $15
- Claude batch: 5M √ó $1.5/M = **$7.50** (—ç–∫–æ–Ω–æ–º–∏—è $7.50)
- Claude batch + prompt caching: **~$3** (—ç–∫–æ–Ω–æ–º–∏—è $12)

## –ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–≤ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

| –§—É–Ω–∫—Ü–∏—è | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –≠–∫–æ–Ω–æ–º–∏—è | –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ |
|---------|-----------|-----------|----------|-------------------|
| **Prompt Caching (Claude)** | üî¥ –í–´–°–û–ö–ò–ô | –ù–∏–∑–∫–∞—è | 90% –Ω–∞ –ø—Ä–æ–º–ø—Ç–∞—Ö | - |
| **Extended Thinking (Claude)** | üî¥ –í–´–°–û–ö–ò–ô | –ù–∏–∑–∫–∞—è | - | +18% —Ç–æ—á–Ω–æ—Å—Ç—å |
| **Structured Outputs (OpenAI)** | üî¥ –í–´–°–û–ö–ò–ô | –°—Ä–µ–¥–Ω—è—è | - | 100% –≤–∞–ª–∏–¥–Ω—ã–π JSON |
| **Grounding (Gemini)** | üü° –°–†–ï–î–ù–ò–ô | –°—Ä–µ–¥–Ω—è—è | - | –ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ |
| **Batch API** | üü° –°–†–ï–î–ù–ò–ô | –í—ã—Å–æ–∫–∞—è | 50% –æ–±—â–∞—è | - |
| **Implicit Caching (Gemini)** | üü¢ –ù–ò–ó–ö–ò–ô | –ù–µ—Ç (–∞–≤—Ç–æ) | –ë–µ—Å–ø–ª–∞—Ç–Ω–æ | - |

## –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–ª–∞–Ω –≤–Ω–µ–¥—Ä–µ–Ω–∏—è

### –§–∞–∑–∞ 1: –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (1-2 –Ω–µ–¥–µ–ª–∏)

1. **–ù–µ–¥–µ–ª—è 1:**
   - ‚úÖ –í–Ω–µ–¥—Ä–∏—Ç—å Prompt Caching –¥–ª—è Claude –≤–æ –≤—Å–µ—Ö 6 –∞–≥–µ–Ω—Ç–∞—Ö
   - ‚úÖ –î–æ–±–∞–≤–∏—Ç—å Extended Thinking –¥–ª—è 3 —Å–ª–æ–∂–Ω—ã—Ö —ç—Ç–∞–ø–æ–≤
   - –û–∂–∏–¥–∞–µ–º–∞—è —ç–∫–æ–Ω–æ–º–∏—è: 85-90% –Ω–∞ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è –ø—Ä–æ–º–ø—Ç–∞—Ö
   - –£–ª—É—á—à–µ–Ω–∏–µ: +15-20% —Ç–æ—á–Ω–æ—Å—Ç—å —Å–ª–æ–∂–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤

2. **–ù–µ–¥–µ–ª—è 2:**
   - ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Structured Outputs –¥–ª—è –≤—Å–µ—Ö —Å—Ö–µ–º –æ—Ç—á–µ—Ç–æ–≤
   - ‚úÖ –°–æ–∑–¥–∞—Ç—å Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è 6 —Ç–∏–ø–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã
   - –†–µ–∑—É–ª—å—Ç–∞—Ç: 100% –≥–∞—Ä–∞–Ω—Ç–∏—è –≤–∞–ª–∏–¥–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞

### –§–∞–∑–∞ 2: –ê–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (1 –Ω–µ–¥–µ–ª—è)

3. **–ù–µ–¥–µ–ª—è 3:**
   - ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å Gemini Grounding –≤ –§–∏–ª—å—Ç—Ä –°–∏—Å—Ç–µ–º–Ω–æ–π –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
   - ‚úÖ –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞
   - –†–µ–∑—É–ª—å—Ç–∞—Ç: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ adilet.zan.kz

### –§–∞–∑–∞ 3: –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ (2 –Ω–µ–¥–µ–ª–∏)

4. **–ù–µ–¥–µ–ª–∏ 4-5:**
   - ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Batch API processor
   - ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≤—Å–µ—Ö —Ç—Ä–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
   - ‚úÖ –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
   - –†–µ–∑—É–ª—å—Ç–∞—Ç: –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–µ—Å—è—Ç–∫–∏ –ù–ü–ê —Å —ç–∫–æ–Ω–æ–º–∏–µ–π 50%

## –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏

### –î–ª—è —Ç–∏–ø–∏—á–Ω–æ–≥–æ –ù–ü–ê (100 —Å—Ç–∞—Ç–µ–π, 6 —ç—Ç–∞–ø–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã):

**–ë–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π:**
- –°—Ç–æ–∏–º–æ—Å—Ç—å: ~$15-20
- –í—Ä–µ–º—è: 30-40 –º–∏–Ω—É—Ç
- –ö–∞—á–µ—Å—Ç–≤–æ: –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
- –ì–∞—Ä–∞–Ω—Ç–∏—è —Ñ–æ—Ä–º–∞—Ç–∞: –ù–µ—Ç

**–° –ø–æ–ª–Ω—ã–º–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏:**
- –°—Ç–æ–∏–º–æ—Å—Ç—å: ~$2-3 (—ç–∫–æ–Ω–æ–º–∏—è 85%)
- –í—Ä–µ–º—è: 25-35 –º–∏–Ω—É—Ç (—Å thinking)
- –ö–∞—á–µ—Å—Ç–≤–æ: +18% —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö
- –ì–∞—Ä–∞–Ω—Ç–∏—è —Ñ–æ—Ä–º–∞—Ç–∞: 100%
- –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å: –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ Google Search
- –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å: –í–∏–¥–∏–º—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏

### –î–ª—è –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (100 –ù–ü–ê –≤ batch —Ä–µ–∂–∏–º–µ):

**–ë–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π:**
- –°—Ç–æ–∏–º–æ—Å—Ç—å: ~$1,500-2,000
- –í—Ä–µ–º—è: –†–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
- –†–∏—Å–∫: –ú–æ–∂–µ—Ç —É–ø–µ—Ä–µ—Ç—å—Å—è –≤ rate limits

**–° batch + caching:**
- –°—Ç–æ–∏–º–æ—Å—Ç—å: ~$300-400 (—ç–∫–æ–Ω–æ–º–∏—è 80%)
- –í—Ä–µ–º—è: –î–æ 24 —á–∞—Å–æ–≤ (—Ñ–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)
- –ì–∞—Ä–∞–Ω—Ç–∏—è: Dedicated quota, –Ω–µ—Ç rate limits

## –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–Ω–µ–¥—Ä–∏—Ç—å (–∫—Ä–∏—Ç–∏—á–Ω–æ):

1. ‚úÖ **Prompt Caching (Claude)** - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏—è –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏
2. ‚úÖ **Extended Thinking (Claude)** - –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞
3. ‚úÖ **Structured Outputs (OpenAI)** - –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

### –û—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω–æ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):

4. ‚úÖ **Grounding (Gemini)** - –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
5. ‚úÖ **Batch API** - –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—Ä—Ö–∏–≤–æ–≤ –ù–ü–ê

### –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç:

6. ‚úÖ **Implicit Caching (Gemini)** - –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

### –ò—Ç–æ–≥–æ–≤–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å:

**–°—Ç—Ä–∏–º–∏–Ω–≥ vs Batch:**
- **Streaming** - –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã, real-time feedback
- **Batch** - –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏, —ç–∫–æ–Ω–æ–º–∏—è 50%
- **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±–∞ —Ä–µ–∂–∏–º–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ü–µ–Ω–∞—Ä–∏—è

**ROI –≤–Ω–µ–¥—Ä–µ–Ω–∏—è:**
- –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞: 4-5 –Ω–µ–¥–µ–ª—å
- –≠–∫–æ–Ω–æ–º–∏—è: 80-90% –Ω–∞ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–π —Ä–∞–±–æ—Ç–µ
- –ö–∞—á–µ—Å—Ç–≤–æ: +15-20% —Ç–æ—á–Ω–æ—Å—Ç—å
- –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å: 100% –≥–∞—Ä–∞–Ω—Ç–∏—è —Ñ–æ—Ä–º–∞—Ç–∞

–°–∏—Å—Ç–µ–º–∞ —Å—Ç–∞–Ω–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ –∏ –¥–µ—à–µ–≤–ª–µ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –∞–Ω–∞–ª–∏–∑–∞.
